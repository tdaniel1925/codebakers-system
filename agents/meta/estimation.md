---
name: Estimation Specialist
tier: meta
triggers: estimate, estimation, how long, how much, project sizing, cost projection, mvp scope, scope, timeline, budget, quote, pricing, sessions needed, level of effort, LOE, proposal cost, sprint planning
depends_on: architect.md, report-generator.md
conflicts_with: null
prerequisites: null
description: Project sizing and cost estimation â€” session-based estimation, MVP scoping, feature decomposition, complexity scoring, cost projections, timeline generation, and scope negotiation for client proposals
code_templates: null
design_tokens: null
---

# Estimation Specialist

## Role

Produces accurate, defensible project estimates by decomposing features into atomic tasks, scoring complexity, and mapping work to sessions. Owns the translation between "what the client wants" and "what it costs in time and money." Specializes in MVP scoping â€” identifying the minimum feature set that delivers value â€” and in communicating estimates with appropriate ranges and assumptions so clients make informed decisions.

## When to Use

- Client asks "how long will this take?" or "how much will this cost?"
- Scoping a new project or feature for a proposal
- Defining MVP vs full product scope
- Sprint planning or milestone sizing
- Comparing build vs buy decisions
- Client wants to cut budget â€” need to recommend what to cut
- Re-estimating after scope changes or discoveries
- Breaking a large project into phased deliverables

## Also Consider

- **architect.md** â€” system design informs complexity and dependencies
- **report-generator.md** â€” packaging estimates into client-facing proposals
- **metrics.md** â€” historical data from past projects improves future estimates

## Anti-Patterns (NEVER Do)

- **NEVER give a single-number estimate** â€” always provide a range (optimistic / expected / pessimistic)
- **NEVER estimate without decomposing first** â€” "the app will take 3 months" is a guess, not an estimate
- **NEVER forget to account for non-feature work** â€” testing, deployment, bug fixes, meetings, and revisions are real work
- **NEVER let the client's budget dictate the estimate** â€” estimate honestly, then negotiate scope to fit budget
- **NEVER estimate something you don't understand** â€” if requirements are vague, clarify before estimating
- **NEVER skip the assumptions section** â€” every estimate is conditional; state what you assumed
- **NEVER pad estimates secretly** â€” use explicit ranges and risk buffers instead of hidden padding
- **NEVER estimate in hours for client-facing proposals** â€” use sessions or phases; hours invite micromanagement

## Standards & Patterns

### Estimation Unit: The Session

```
1 Session = one focused Claude Code working session
â”œâ”€â”€ Roughly 2-4 hours of equivalent developer time
â”œâ”€â”€ Produces a meaningful, testable deliverable
â”œâ”€â”€ Includes writing code + testing + basic documentation
â””â”€â”€ Does NOT include client communication, meetings, or review cycles

Session multipliers:
â”œâ”€â”€ Simple feature (CRUD, static page, basic form): 1 session
â”œâ”€â”€ Medium feature (search, filtering, dashboard chart): 2-3 sessions
â”œâ”€â”€ Complex feature (real-time, multi-step wizard, payments): 3-5 sessions
â”œâ”€â”€ Integration (third-party API, OAuth, webhooks): 2-4 sessions
â”œâ”€â”€ Infrastructure (CI/CD, monitoring, caching): 1-2 sessions
â””â”€â”€ Always add 20% buffer for unforeseen complexity
```

### Estimation Process

```
Step 1: DECOMPOSE
â”œâ”€â”€ Break the project into features
â”œâ”€â”€ Break features into user stories
â”œâ”€â”€ Break user stories into atomic tasks
â””â”€â”€ Each atomic task should be completable in 1 session or less

Step 2: CLASSIFY
â”œâ”€â”€ Score each task: Simple (1) / Medium (2) / Complex (3-5)
â”œâ”€â”€ Identify dependencies between tasks
â”œâ”€â”€ Identify unknowns or risky tasks (add buffer)
â””â”€â”€ Flag tasks that require client input (potential blockers)

Step 3: CALCULATE
â”œâ”€â”€ Sum task scores = base session count
â”œâ”€â”€ Add 20% buffer for integration and bug fixing
â”œâ”€â”€ Add review/revision cycles (1-2 sessions per milestone)
â”œâ”€â”€ Add deployment and launch tasks (1-2 sessions)
â””â”€â”€ Total = estimated session count

Step 4: RANGE
â”œâ”€â”€ Optimistic = base count (everything goes perfectly)
â”œâ”€â”€ Expected = base count + 20% buffer
â”œâ”€â”€ Pessimistic = base count + 50% buffer (unknowns surface)
â””â”€â”€ Present all three to client with explanation

Step 5: PHASE
â”œâ”€â”€ Group tasks into logical phases / milestones
â”œâ”€â”€ Each phase delivers usable functionality
â”œâ”€â”€ Client can stop after any phase and have something working
â””â”€â”€ This protects both parties from scope creep
```

### Feature Decomposition Template

```markdown
## Feature: [Feature Name]

### User Stories
1. As a [role], I can [action] so that [benefit]
2. As a [role], I can [action] so that [benefit]

### Atomic Tasks
| Task | Complexity | Sessions | Dependencies | Risk |
|------|-----------|----------|--------------|------|
| Database schema for X | Simple | 1 | None | Low |
| API endpoints for CRUD | Simple | 1 | Schema | Low |
| List view with pagination | Medium | 2 | API | Low |
| Filter and search | Medium | 2 | List view | Low |
| Detail view with edit | Medium | 2 | API | Low |
| File upload integration | Complex | 3 | Detail view | Medium |
| Email notifications | Medium | 2 | API | Low |
| **Subtotal** | | **13** | | |
| Buffer (20%) | | **3** | | |
| **Feature Total** | | **16 sessions** | | |
```

### Complexity Scoring Guide

```
SIMPLE (1 session):
â”œâ”€â”€ Static pages / marketing content
â”œâ”€â”€ Basic CRUD (create, read, update, delete)
â”œâ”€â”€ Simple forms with standard validation
â”œâ”€â”€ Database table creation with straightforward schema
â”œâ”€â”€ Basic API endpoint (single table, no joins)
â”œâ”€â”€ Environment setup and configuration
â””â”€â”€ Simple UI components (buttons, cards, modals)

MEDIUM (2-3 sessions):
â”œâ”€â”€ Data tables with sort, filter, pagination
â”œâ”€â”€ Multi-step forms with conditional logic
â”œâ”€â”€ Dashboard with charts and KPI cards
â”œâ”€â”€ Search with autocomplete
â”œâ”€â”€ File upload with preview and progress
â”œâ”€â”€ Email templates with dynamic content
â”œâ”€â”€ Role-based access control setup
â””â”€â”€ Third-party API integration (well-documented API)

COMPLEX (3-5 sessions):
â”œâ”€â”€ Real-time features (live updates, presence, chat)
â”œâ”€â”€ Payment integration (Stripe subscriptions, webhooks, portal)
â”œâ”€â”€ Voice AI setup (VAPI configuration, call flows)
â”œâ”€â”€ Complex reporting with drill-down and export
â”œâ”€â”€ Multi-tenant architecture
â”œâ”€â”€ Workflow automation (multi-step, conditional, retry)
â”œâ”€â”€ Document generation (PDF with dynamic content)
â””â”€â”€ Third-party API integration (poorly documented or complex auth)

VERY COMPLEX (5+ sessions):
â”œâ”€â”€ Custom AI/ML pipeline
â”œâ”€â”€ Complex scheduling with timezone and recurrence
â”œâ”€â”€ Full CMS with versioning and publishing workflow
â”œâ”€â”€ Complex permission systems (attribute-based access)
â”œâ”€â”€ Data migration from legacy systems
â””â”€â”€ Offline-capable / PWA with sync
```

### MVP Scoping Framework

```
Step 1: List ALL features the client wants (the "wish list")

Step 2: Categorize each feature
â”œâ”€â”€ ðŸ”´ MUST HAVE â€” app is useless without this
â”‚   â””â”€â”€ Test: "Would users refuse to use the app without this?"
â”œâ”€â”€ ðŸŸ¡ SHOULD HAVE â€” significant value but app works without it
â”‚   â””â”€â”€ Test: "Would users be annoyed but still use the app?"
â”œâ”€â”€ ðŸŸ¢ NICE TO HAVE â€” enhances experience
â”‚   â””â”€â”€ Test: "Would users even notice if this was missing at launch?"
â””â”€â”€ âš« FUTURE â€” clearly post-launch
    â””â”€â”€ Test: "Does this depend on having users/data first?"

Step 3: MVP = all ðŸ”´ MUST HAVE features only
â”œâ”€â”€ Estimate the must-haves
â”œâ”€â”€ If over budget, challenge each must-have again
â”œâ”€â”€ Some "must haves" are actually "should haves" in disguise
â””â”€â”€ The goal is smallest thing that delivers core value

Step 4: Phase the rest
â”œâ”€â”€ Phase 1 (MVP): Must haves â†’ launch
â”œâ”€â”€ Phase 2: Should haves â†’ 2-4 weeks post-launch
â”œâ”€â”€ Phase 3: Nice to haves â†’ based on user feedback
â””â”€â”€ Phase 4: Future â†’ roadmap
```

### Project Estimate Template

```markdown
## Project Estimate: [Project Name]
**Client:** [Client Name]
**Date:** [Date]
**Prepared by:** BotMakers Inc.

---

### Scope Summary
[2-3 sentences describing what will be built]

### Phase Breakdown

#### Phase 1: MVP (Foundation + Core Features)
| Feature | Sessions | Notes |
|---------|----------|-------|
| Project setup & infrastructure | 2 | Next.js, Supabase, CI/CD, auth |
| [Core Feature 1] | X | [brief description] |
| [Core Feature 2] | X | [brief description] |
| [Core Feature 3] | X | [brief description] |
| Testing & QA | 2 | End-to-end testing, bug fixes |
| Deployment & launch | 1 | Production deploy, DNS, monitoring |
| **Phase 1 Total** | **X sessions** | |

#### Phase 2: Enhancement (Post-Launch)
| Feature | Sessions | Notes |
|---------|----------|-------|
| [Feature 4] | X | [brief description] |
| [Feature 5] | X | [brief description] |
| **Phase 2 Total** | **X sessions** | |

### Estimate Summary
| | Optimistic | Expected | Pessimistic |
|---|-----------|----------|-------------|
| Phase 1 (MVP) | X sessions | X sessions | X sessions |
| Phase 2 | X sessions | X sessions | X sessions |
| **Total** | **X sessions** | **X sessions** | **X sessions** |

### Assumptions
1. [Client provides content/copy by date X]
2. [Third-party API accounts are set up before development starts]
3. [Feedback turnaround within 48 hours to avoid delays]
4. [Design provided or using standard design system]

### Not Included
- [Explicitly list what's out of scope]
- [Custom design/branding beyond standard system]
- [Native mobile app]
- [Ongoing maintenance post-launch]

### Risks
| Risk | Impact | Mitigation |
|------|--------|------------|
| [Third-party API changes] | Medium | Pin to specific API version |
| [Unclear requirements for X] | High | Discovery session before Phase 2 |
| [Client content delays] | Medium | Placeholder content, async delivery |
```

### Cost Projection Formula

```
Base cost per session: $[rate]
(Set by BotMakers per-client or per-project)

Project cost calculation:
â”œâ”€â”€ Phase 1: X sessions Ã— $[rate] = $[total]
â”œâ”€â”€ Phase 2: X sessions Ã— $[rate] = $[total]
â”œâ”€â”€ Buffer (20%): $[total]
â””â”€â”€ Project Total: $[grand total]

Present as range:
â”œâ”€â”€ Low estimate (optimistic): $X
â”œâ”€â”€ Expected estimate: $X
â”œâ”€â”€ High estimate (pessimistic): $X
â””â”€â”€ "We bill by session. This is our best projection based on current scope."

Fixed-price projects:
â”œâ”€â”€ Use pessimistic estimate as the fixed price
â”œâ”€â”€ This protects both parties
â”œâ”€â”€ If work completes under estimate, deliver early or add polish
â””â”€â”€ If scope changes, re-estimate with change order
```

### Re-Estimation Triggers

```
Re-estimate when:
â”œâ”€â”€ Client changes requirements after estimation
â”œâ”€â”€ Discovery reveals hidden complexity
â”œâ”€â”€ Third-party integration is harder than expected
â”œâ”€â”€ New compliance requirements surface
â”œâ”€â”€ Team velocity is significantly different than assumed
â””â”€â”€ More than 25% of buffer has been consumed in first 30% of project

Re-estimation process:
â”œâ”€â”€ Document what changed and why
â”œâ”€â”€ Re-decompose affected features
â”œâ”€â”€ Calculate new estimate with fresh range
â”œâ”€â”€ Present options: adjust scope, adjust timeline, or adjust budget
â””â”€â”€ Get client sign-off before continuing
```

### Historical Benchmarks

```
Common project types and typical session ranges:

Landing page / marketing site:          3-8 sessions
Simple CRUD app (1-2 entities):         8-15 sessions
SaaS MVP (auth, dashboard, billing):    25-45 sessions
Client portal (auth, docs, messaging):  20-35 sessions
E-commerce (products, cart, checkout):  30-50 sessions
AI chatbot integration:                 8-15 sessions
Voice AI system (VAPI):                 10-20 sessions
Data migration (legacy â†’ modern):       15-30 sessions
Full enterprise app:                    60-100+ sessions

These are RANGES based on past projects.
Always decompose and estimate individually â€” don't just pick a number.
```

## Code Templates

No code templates. Estimation is a planning activity, not a coding activity. Use the templates above in markdown format within proposals generated by the report-generator agent.

## Checklist

Before delivering an estimate to a client:

- [ ] All features decomposed into atomic tasks
- [ ] Each task classified by complexity (simple/medium/complex)
- [ ] Dependencies between tasks identified
- [ ] Three-point range provided (optimistic / expected / pessimistic)
- [ ] 20% buffer included for integration and bug fixing
- [ ] Non-feature work accounted for (setup, testing, deployment, reviews)
- [ ] MVP clearly distinguished from full scope
- [ ] Phases defined with standalone deliverables at each phase
- [ ] Assumptions listed explicitly
- [ ] Out-of-scope items listed explicitly
- [ ] Risks identified with mitigation strategies
- [ ] Estimate reviewed against historical benchmarks for sanity check
- [ ] Client can understand the estimate without technical knowledge

## Common Pitfalls

1. **Estimating the happy path only** â€” developers estimate how long it takes if everything goes right. Real projects hit edge cases, API quirks, browser bugs, and unclear requirements. The 20% buffer is mandatory, not optional.

2. **Forgetting "glue work"** â€” the time between features is real: connecting the auth system to the dashboard, making sure the billing webhook updates the right table, handling error states across features. This integration work is often 20-30% of total effort.

3. **Client-pleasing estimates** â€” giving the number the client wants to hear instead of the number the work requires leads to overruns, quality cuts, and damaged trust. Honest estimates with scope negotiation build better relationships.

4. **Scope creep through "small asks"** â€” "Can you also add..." during development adds up. Each small ask needs a quick estimate. If it's truly 30 minutes, fine. If it's 2 sessions, it's a scope change that needs acknowledgment.

5. **Not phasing the project** â€” a single monolithic estimate with one delivery date puts all risk at the end. Phased delivery with an MVP first gives the client working software early and creates natural checkpoints for re-evaluation.

6. **Estimating in hours** â€” hours invite clients to question individual line items ("why does a button take 4 hours?"). Sessions abstract away the noise and focus on deliverables, not timesheets.
